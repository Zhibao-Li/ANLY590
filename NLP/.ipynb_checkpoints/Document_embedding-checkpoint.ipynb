{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Spliting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows',None)\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "      <th>label_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_129225211</td>\n",
       "      <td>0000a68812bc7e98c42888dfb1c07da0.jpg</td>\n",
       "      <td>94974f937d4c2433</td>\n",
       "      <td>Paper Bag Victoria Secret</td>\n",
       "      <td>249114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_3386243561</td>\n",
       "      <td>00039780dfc94d01db8676fe789ecd05.jpg</td>\n",
       "      <td>af3f9460c2838f0f</td>\n",
       "      <td>Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...</td>\n",
       "      <td>2937985045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2288590299</td>\n",
       "      <td>000a190fdd715a2a36faed16e2c65df7.jpg</td>\n",
       "      <td>b94cb00ed3e50f78</td>\n",
       "      <td>Maling TTS Canned Pork Luncheon Meat 397 gr</td>\n",
       "      <td>2395904891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_2406599165</td>\n",
       "      <td>00117e4fc239b1b641ff08340b429633.jpg</td>\n",
       "      <td>8514fc58eafea283</td>\n",
       "      <td>Daster Batik Lengan pendek - Motif Acak / Camp...</td>\n",
       "      <td>4093212188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_3369186413</td>\n",
       "      <td>00136d1cf4edede0203f32f05f660588.jpg</td>\n",
       "      <td>a6f319f924ad708c</td>\n",
       "      <td>Nescafe \\xc3\\x89clair Latte 220ml</td>\n",
       "      <td>3648931069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         posting_id                                 image       image_phash  \\\n",
       "0   train_129225211  0000a68812bc7e98c42888dfb1c07da0.jpg  94974f937d4c2433   \n",
       "1  train_3386243561  00039780dfc94d01db8676fe789ecd05.jpg  af3f9460c2838f0f   \n",
       "2  train_2288590299  000a190fdd715a2a36faed16e2c65df7.jpg  b94cb00ed3e50f78   \n",
       "3  train_2406599165  00117e4fc239b1b641ff08340b429633.jpg  8514fc58eafea283   \n",
       "4  train_3369186413  00136d1cf4edede0203f32f05f660588.jpg  a6f319f924ad708c   \n",
       "\n",
       "                                               title  label_group  \n",
       "0                          Paper Bag Victoria Secret    249114794  \n",
       "1  Double Tape 3M VHB 12 mm x 4,5 m ORIGINAL / DO...   2937985045  \n",
       "2        Maling TTS Canned Pork Luncheon Meat 397 gr   2395904891  \n",
       "3  Daster Batik Lengan pendek - Motif Acak / Camp...   4093212188  \n",
       "4                  Nescafe \\xc3\\x89clair Latte 220ml   3648931069  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The samples in test_csv will not be used for training & validation\n",
    "train_csv=pd.read_csv('Data/train.csv')\n",
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_id</th>\n",
       "      <th>image</th>\n",
       "      <th>image_phash</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_2255846744</td>\n",
       "      <td>0006c8e5462ae52167402bac1c2e916e.jpg</td>\n",
       "      <td>ecc292392dc7687a</td>\n",
       "      <td>Edufuntoys - CHARACTER PHONE ada lampu dan mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_3588702337</td>\n",
       "      <td>0007585c4d0f932859339129f709bfdc.jpg</td>\n",
       "      <td>e9968f60d2699e2c</td>\n",
       "      <td>(Beli 1 Free Spatula) Masker Komedo | Blackhea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_4015706929</td>\n",
       "      <td>0008377d3662e83ef44e1881af38b879.jpg</td>\n",
       "      <td>ba81c17e3581cabe</td>\n",
       "      <td>READY Lemonilo Mie instant sehat kuah dan goreng</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        posting_id                                 image       image_phash  \\\n",
       "0  test_2255846744  0006c8e5462ae52167402bac1c2e916e.jpg  ecc292392dc7687a   \n",
       "1  test_3588702337  0007585c4d0f932859339129f709bfdc.jpg  e9968f60d2699e2c   \n",
       "2  test_4015706929  0008377d3662e83ef44e1881af38b879.jpg  ba81c17e3581cabe   \n",
       "\n",
       "                                               title  \n",
       "0  Edufuntoys - CHARACTER PHONE ada lampu dan mus...  \n",
       "1  (Beli 1 Free Spatula) Masker Komedo | Blackhea...  \n",
       "2   READY Lemonilo Mie instant sehat kuah dan goreng  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The samples in test_csv will not be used during training\n",
    "test_csv=pd.read_csv('Data/test.csv')\n",
    "test_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_group</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994676122</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1163569239</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1141798720</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159351600</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>562358068</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_group  count\n",
       "0    994676122     51\n",
       "1   1163569239     51\n",
       "2   1141798720     51\n",
       "3    159351600     51\n",
       "4    562358068     51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Count every label_group\n",
    "train_csv.label_group.value_counts().reset_index().rename(columns={'index':'label_group','label_group':'count'}).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{994676122: 5,\n",
       " 1163569239: 5,\n",
       " 1141798720: 5,\n",
       " 159351600: 5,\n",
       " 562358068: 5,\n",
       " 3113678103: 5,\n",
       " 3627744656: 5,\n",
       " 3206118280: 4,\n",
       " 1733221456: 4,\n",
       " 1166650192: 4,\n",
       " 1091404026: 4,\n",
       " 3489985175: 4,\n",
       " 1237550763: 3,\n",
       " 1746655739: 3,\n",
       " 452508504: 3,\n",
       " 731330024: 3,\n",
       " 4184214313: 3,\n",
       " 2008989859: 3,\n",
       " 1575763518: 3,\n",
       " 66247839: 3,\n",
       " 871679006: 3,\n",
       " 952183003: 3,\n",
       " 2259957740: 3,\n",
       " 3001123709: 3,\n",
       " 2999794436: 3,\n",
       " 2935813666: 3,\n",
       " 3926100920: 3,\n",
       " 656698835: 3,\n",
       " 1226500780: 3,\n",
       " 997220911: 3,\n",
       " 1201602115: 2,\n",
       " 821583868: 2,\n",
       " 3717044186: 2,\n",
       " 3868183614: 2,\n",
       " 1135976474: 2,\n",
       " 3326267479: 2,\n",
       " 3040690230: 2,\n",
       " 927285629: 2,\n",
       " 1306578136: 2,\n",
       " 2156459496: 2,\n",
       " 4141124289: 2,\n",
       " 2123332638: 2,\n",
       " 418991059: 2,\n",
       " 1569494229: 2,\n",
       " 3441184770: 2,\n",
       " 777596345: 2,\n",
       " 1744240905: 2,\n",
       " 2956941947: 2,\n",
       " 1065450055: 2,\n",
       " 1544174053: 2,\n",
       " 1088754866: 2,\n",
       " 2911646536: 2,\n",
       " 4277487223: 2,\n",
       " 3433277712: 2,\n",
       " 962477933: 2,\n",
       " 1285119273: 2,\n",
       " 4038613836: 2,\n",
       " 2748623227: 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only sample those label_group which has more than 20 samples\n",
    "test_ratio=0.1\n",
    "label_count=train_csv.label_group.value_counts().reset_index().rename(columns={'index':'label_group','label_group':'count'})\n",
    "sample_num={}\n",
    "\n",
    "for i in range(label_count.shape[0]):\n",
    "    num_to_sample=label_count['count'].iloc[i]*test_ratio\n",
    "    if num_to_sample<2:continue\n",
    "    sample_num[label_count['label_group'].iloc[i]]=int(num_to_sample)\n",
    "\n",
    "sample_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingSet Size:34085\n",
      "ValidationSet Size:165\n"
     ]
    }
   ],
   "source": [
    "valid_idx=[list(np.where(train_csv['label_group']==label)[0][:sample_num[label]]) for label in sample_num]\n",
    "valid_idx=[idx for group in valid_idx for idx in group]\n",
    "\n",
    "train_idx=[i for i in range(train_csv.shape[0]) if i not in valid_idx]\n",
    "\n",
    "print('TrainingSet Size:{}'.format(len(train_idx)))\n",
    "print('ValidationSet Size:{}'.format(len(valid_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train=train_csv.iloc[train_idx,:-1],train_csv.iloc[train_idx,-1]\n",
    "X_valid,y_valid=train_csv.iloc[valid_idx,:-1],train_csv.iloc[valid_idx,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Reference: https://towardsdatascience.com/cleaning-text-data-with-python-b69b47b97b76\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "# # In case of any corpus are missing \n",
    "stop_words = stopwords.words(\"english\")\n",
    "def text_preproc(x):\n",
    "    x = x.lower()\n",
    "    x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "    x = x.encode('ascii', 'ignore').decode()\n",
    "    x = re.sub(r'https*\\S+', ' ', x)\n",
    "    x = re.sub(r'@\\S+', ' ', x)\n",
    "    x = re.sub(r'#\\S+', ' ', x)\n",
    "    x = re.sub(r'\\'\\w+', '', x)\n",
    "    x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "    x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "    x = re.sub(r'\\s{2,}', ' ', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_apply(docs):\n",
    "    for i, doc in enumerate(docs):\n",
    "        docs[i] = text_preproc(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = np.array(X_train['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = np.array(X_valid['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_apply(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['paper bag victoria secret',\n",
       "       'double tape vhb mm x original double foam tape',\n",
       "       'maling tts canned pork luncheon meat gr', ...,\n",
       "       'khanzaacc robot subwoofer bass metal wired headset',\n",
       "       'kaldu non msg halal mama kamu ayam kampung sapi lokal jamur bkn alsultan biocell ',\n",
       "       'flex tape pelapis bocor isolasi ajaib anti bocor'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_apply(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.c_[train_text,np.array(y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34085, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.c_[test_text,np.array(y_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['paper bag victoria secret', 249114794],\n",
       "       ['double tape vhb mm x original double foam tape', 2937985045],\n",
       "       ['maling tts canned pork luncheon meat gr', 2395904891],\n",
       "       ['daster batik lengan pendek motif acak campur leher kancing batik karakter alhadi',\n",
       "        4093212188],\n",
       "       ['nescafe latte ', 3648931069]], dtype=object)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['karet kucir premium', 994676122],\n",
       "       [' karet ikat rambut elastis untuk wanita', 994676122],\n",
       "       [' pcs ikat rambut karet polos elastis gaya korea untuk wanita',\n",
       "        994676122],\n",
       "       [' pcs ikat rambut korea karet polos elastis gaya korea untuk wanita',\n",
       "        994676122],\n",
       "       ['korea women children hair tie head rope karet gelang elastis',\n",
       "        994676122]], dtype=object)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vectorizing: Self-trained document embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing\n",
    "# Code Reference: ANLY 580 Natural Language Processing Lab5\n",
    "import gensim\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "K = 64\n",
    "word_frequency_threshold = 2\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "model = Doc2Vec(vector_size=K, min_count=word_frequency_threshold, epochs=epochs)\n",
    "text_list = []\n",
    "for i, line in enumerate(train_data[:,0]):\n",
    "    tokens = gensim.utils.simple_preprocess(line)\n",
    "    text_list.append(gensim.models.doc2vec.TaggedDocument(tokens, [i]))\n",
    "model.build_vocab(text_list)\n",
    "model.train(text_list, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_embedding_vector\n",
    "embedding_vector = np.array([model.infer_vector(i.split()) for i in train_data[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34085, 64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00122813, -0.02922335,  0.01609793,  0.0035479 ,  0.0135329 ,\n",
       "         0.00858887,  0.00972958, -0.01786955, -0.00997095, -0.00200482,\n",
       "        -0.02523364, -0.0041339 , -0.02168355, -0.00059627, -0.01850777,\n",
       "         0.03147927, -0.01674778, -0.0033539 , -0.04341891,  0.0438098 ,\n",
       "         0.03923074,  0.03614574, -0.02088674, -0.05020263, -0.04269053,\n",
       "         0.01221717, -0.06456788,  0.00186756,  0.0286314 , -0.03083886,\n",
       "         0.0176802 , -0.01986532, -0.00576735, -0.01072335, -0.03602539,\n",
       "         0.06110099,  0.03023976, -0.04990058,  0.01029437,  0.0385104 ,\n",
       "         0.03461859, -0.02080715,  0.02517138, -0.03622035,  0.02491518,\n",
       "         0.01342856,  0.03866169, -0.0948117 ,  0.02131087,  0.00050993,\n",
       "         0.00973766, -0.01686111, -0.00440951,  0.0214761 ,  0.02242767,\n",
       "        -0.0215011 , -0.00707173, -0.0392006 , -0.01723917, -0.01290667,\n",
       "        -0.00744743, -0.02927901, -0.02212649, -0.00427793],\n",
       "       [ 0.0415769 , -0.06845216,  0.07252624,  0.01788334,  0.01246138,\n",
       "        -0.02252248, -0.05934149, -0.04708936, -0.03681168,  0.01603013,\n",
       "        -0.04661334,  0.00998162, -0.03817268, -0.02617125, -0.0307239 ,\n",
       "         0.02664099, -0.04208653, -0.0501866 , -0.0594487 ,  0.08112179,\n",
       "         0.04627427,  0.03114109, -0.02762114, -0.10034513, -0.03914782,\n",
       "         0.00915998, -0.04392282, -0.02061898,  0.03913957, -0.0233608 ,\n",
       "         0.10294938, -0.00581015, -0.05932583, -0.02385125,  0.00703324,\n",
       "        -0.01654646,  0.00383873, -0.05875576, -0.0155629 ,  0.03189437,\n",
       "         0.06827054, -0.06225039, -0.02144928,  0.0102187 ,  0.04445414,\n",
       "        -0.06055537,  0.09043432, -0.11455153, -0.00425425, -0.00499318,\n",
       "        -0.00018831,  0.00740975, -0.07745073,  0.03262517,  0.04473716,\n",
       "        -0.01363247,  0.00198448,  0.01414316, -0.0568584 ,  0.06473764,\n",
       "        -0.06261579,  0.05433308,  0.03813776, -0.05214965],\n",
       "       [ 0.11191132, -0.08400629,  0.03577673,  0.04995253,  0.03017981,\n",
       "        -0.09362771, -0.00909737, -0.03045429, -0.08781053, -0.01444924,\n",
       "         0.06834623, -0.05681759, -0.00764924, -0.06439489, -0.04213419,\n",
       "         0.11209972, -0.0787401 , -0.05060347, -0.04793039,  0.09601571,\n",
       "         0.0950808 ,  0.12774529, -0.04031388, -0.10992032, -0.04283229,\n",
       "         0.0638653 , -0.08875903, -0.02687682,  0.04877724, -0.03796417,\n",
       "         0.00799408,  0.02975072, -0.0342195 , -0.07863464, -0.01820379,\n",
       "        -0.03012076,  0.0317614 , -0.00240484,  0.04210384,  0.0249749 ,\n",
       "         0.05560821,  0.06043427, -0.01120308,  0.0169572 ,  0.16213365,\n",
       "        -0.05569157, -0.02443138, -0.12361266,  0.01062981,  0.06276354,\n",
       "         0.06401538, -0.00439888,  0.01291624,  0.05393551, -0.02662611,\n",
       "        -0.04160846,  0.04669245, -0.04915295, -0.05151949,  0.09291723,\n",
       "        -0.07327584, -0.01896926,  0.01070741,  0.05685844]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first three documents/titles embedding vector\n",
    "embedding_vector[:3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_embedding_vector\n",
    "embedding_vector_test = np.array([model.infer_vector(i.split()) for i in test_data[:,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vector_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Find Similar items based on embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_product(product_title_description, top_n=11):\n",
    "    doc_vector = model.infer_vector(product_title_description)\n",
    "    sims = model.dv.most_similar([doc_vector], topn=top_n)\n",
    "    return sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paper', 'bag', 'victoria', 'secret']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0,0].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.8270717263221741),\n",
       " (4860, 0.7933609485626221),\n",
       " (32996, 0.7849490642547607),\n",
       " (5189, 0.7684443593025208),\n",
       " (21839, 0.7584372162818909),\n",
       " (26230, 0.7549862265586853),\n",
       " (30633, 0.7474336624145508),\n",
       " (31336, 0.7390131950378418),\n",
       " (3807, 0.7383760809898376),\n",
       " (6716, 0.738276481628418),\n",
       " (24113, 0.7340051531791687)]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_similar_product(train_data[0,0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimator(data):\n",
    "    counts = 0\n",
    "    for index in range(len(data)):\n",
    "        similar_indexs = [i[0] for i in find_similar_product(data[index,0].split()) if i[0]!=index][:10] # Top 10 similar indexs of A after exclude A itself\n",
    "        predicted_labels = train_data[similar_indexs,1]    # Top 10 predicted labels of A except A itself\n",
    "        if data[index,1] in predicted_labels:       # if the true label of A is in Top 10 similar predicted labels, it is true\n",
    "            counts += 1\n",
    "    accuracy = counts/len(data)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3154173390054276"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show estimation accuracy of train_data\n",
    "estimator(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5212121212121212"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show estimation accuracy of test_data\n",
    "estimator(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top10_similar_index(data):\n",
    "    similar_list = []\n",
    "    for index in range(len(data)):\n",
    "        similar_indexs = [i[0] for i in find_similar_product(data[index,0].split()) if i[0]!=index][:10] # Top 10 similar indexs of A after exclude A itself\n",
    "        predicted_labels = train_data[similar_indexs,1]    # Top 10 predicted labels of A except A itself\n",
    "        similar_list.append(predicted_labels)\n",
    "    return similar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imilar_list = Top10_similar_index(train_data)\n",
    "test_imilar_list = Top10_similar_index(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_data, columns = ['title','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['Top10_similar_indexs'] = train_imilar_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>Top10_similar_indexs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paper bag victoria secret</td>\n",
       "      <td>249114794</td>\n",
       "      <td>[249114794, 1000106726, 1125219914, 1420214137...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>double tape vhb mm x original double foam tape</td>\n",
       "      <td>2937985045</td>\n",
       "      <td>[475342649, 475342649, 475342649, 475342649, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>maling tts canned pork luncheon meat gr</td>\n",
       "      <td>2395904891</td>\n",
       "      <td>[2775619691, 449938131, 1839153978, 1902043911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>daster batik lengan pendek motif acak campur l...</td>\n",
       "      <td>4093212188</td>\n",
       "      <td>[3150867956, 2453599242, 2560881468, 264184112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nescafe latte</td>\n",
       "      <td>3648931069</td>\n",
       "      <td>[191946414, 2220491818, 4025391613, 3740972720...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title       label  \\\n",
       "0                          paper bag victoria secret   249114794   \n",
       "1     double tape vhb mm x original double foam tape  2937985045   \n",
       "2            maling tts canned pork luncheon meat gr  2395904891   \n",
       "3  daster batik lengan pendek motif acak campur l...  4093212188   \n",
       "4                                     nescafe latte   3648931069   \n",
       "\n",
       "                                Top10_similar_indexs  \n",
       "0  [249114794, 1000106726, 1125219914, 1420214137...  \n",
       "1  [475342649, 475342649, 475342649, 475342649, 2...  \n",
       "2  [2775619691, 449938131, 1839153978, 1902043911...  \n",
       "3  [3150867956, 2453599242, 2560881468, 264184112...  \n",
       "4  [191946414, 2220491818, 4025391613, 3740972720...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>Top10_similar_indexs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>karet kucir premium</td>\n",
       "      <td>994676122</td>\n",
       "      <td>[2253967885, 46287381, 3606023430, 3308317766,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>karet ikat rambut elastis untuk wanita</td>\n",
       "      <td>994676122</td>\n",
       "      <td>[2665537113, 3952236600, 426500726, 1897963080...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pcs ikat rambut karet polos elastis gaya kore...</td>\n",
       "      <td>994676122</td>\n",
       "      <td>[3601571834, 3740972720, 665979983, 1179056926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pcs ikat rambut korea karet polos elastis gay...</td>\n",
       "      <td>994676122</td>\n",
       "      <td>[3601571834, 2220491818, 665979983, 3889297911...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>korea women children hair tie head rope karet ...</td>\n",
       "      <td>994676122</td>\n",
       "      <td>[3437394605, 513750353, 3048199336, 1251733888...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title      label  \\\n",
       "0                                karet kucir premium  994676122   \n",
       "1             karet ikat rambut elastis untuk wanita  994676122   \n",
       "2   pcs ikat rambut karet polos elastis gaya kore...  994676122   \n",
       "3   pcs ikat rambut korea karet polos elastis gay...  994676122   \n",
       "4  korea women children hair tie head rope karet ...  994676122   \n",
       "\n",
       "                                Top10_similar_indexs  \n",
       "0  [2253967885, 46287381, 3606023430, 3308317766,...  \n",
       "1  [2665537113, 3952236600, 426500726, 1897963080...  \n",
       "2  [3601571834, 3740972720, 665979983, 1179056926...  \n",
       "3  [3601571834, 2220491818, 665979983, 3889297911...  \n",
       "4  [3437394605, 513750353, 3048199336, 1251733888...  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.DataFrame(test_data, columns = ['title','label'])\n",
    "test_df['Top10_similar_indexs'] = test_imilar_list\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spyder-env-y]",
   "language": "python",
   "name": "conda-env-spyder-env-y-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f03fb33cde30b1e0ff05e494356ca73819bb92d735d3d5a426c7539b071b763"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
